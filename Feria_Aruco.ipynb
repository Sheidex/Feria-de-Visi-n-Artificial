{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96e632f3-ece6-4ba3-be23-0d88c779d745",
   "metadata": {},
   "source": [
    "<h1>Trabajdo Realizado para la Feria</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20666ae8-32f4-4301-8359-0e4a5343eb6f",
   "metadata": {},
   "source": [
    "<h2>Integrantes</h2>\n",
    "<p>Luis Caballero 8-9231440<br>\n",
    "Ángel Cilli<br>\n",
    "Jaime Acosta</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aabf84c-45bb-4253-8f2b-94a30a4bbce0",
   "metadata": {},
   "source": [
    "<p><b>Idea o Concepto:</b>Trabajaremos un reconocedor de \"personal\" dentro del equipo, un Aruco distinto para Jaime Acosta y Luis Caballero, que cuando sean mostrados a la cámara el programa ejecutará distintos enfoques con Aruco.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55855017-2911-44f6-baea-67b6b33d5520",
   "metadata": {},
   "source": [
    "<h2>Detector del Personal</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20498b3e-fd79-48c7-91ad-babb795c0b93",
   "metadata": {},
   "source": [
    "<p>Para el detector de personal usaremos el diccionario <b>DISC_4x4_1000</b>b><br>\n",
    "Marcado ID 15 → Luis Caballero<br>\n",
    "Marcador ID 13 → Jaime Acosta</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34b38b1-ef69-4303-bba0-73f64e5f3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTACIONES\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#AruCO\n",
    "\n",
    "OVERLAY_SIZE_PER = 1\n",
    "\n",
    "# Check for camera calibration data\n",
    "if not os.path.exists('calibration.pckl'):\n",
    "    print(\"Necesitas Calibrar tu Cámara para un buen uso\")\n",
    "    exit()\n",
    "else:\n",
    "    f = open('calibration.pckl', 'rb')\n",
    "    cameraMatrix, distCoeffs = pickle.load(f)\n",
    "    f.close()\n",
    "    if cameraMatrix is None or distCoeffs is None:\n",
    "        print(\"Alguien salio mal. Recalibra tu cámara\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "# Create the ArUco dictionary and parameters:\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_1000) #Detector de Personal\n",
    "aruco_dict2 = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_5X5_1000) #Imagen 3D\n",
    "aruco_dict3 = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_1000) #Filtros\n",
    "parameters = cv2.aruco.DetectorParameters()\n",
    "\n",
    "# Create the video capture object:\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "frame_index = 0;\n",
    "\n",
    "while video_capture.isOpened():\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(gray_frame, aruco_dict, parameters=parameters)\n",
    "\n",
    "    if ids is not None:\n",
    "        for i in range(len(ids)):\n",
    "            if ids[i] == 15:\n",
    "                # Mensaje de bienvenida para Luis Caballero\n",
    "                cv2.putText(img=frame, text=\"Bienvenido Luis\", org=(10, 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1,\n",
    "            color=(102, 102, 255), thickness=2)\n",
    "                #aqui deberia ir lo de filtros\n",
    "            elif ids[i] == 13:\n",
    "                # Mensaje de bienvenida para Jaime Acosta\n",
    "                cv2.putText(img=frame, text=\"Bienvenido Jaime\", org=(10, 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1,\n",
    "            color=(102, 102, 255), thickness=2)\n",
    "                #aqui deberia ir lo del 3D\n",
    "                \n",
    "            else:\n",
    "                #Mensaje de no esta registrado\n",
    "                cv2.putText(img=frame, text=\"Quien tu eres!?\", org=(10, 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1,\n",
    "            color=(102, 102, 255), thickness=2)\n",
    "                \n",
    "\n",
    "    cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "    cv2.imshow('ArUco Marker and Face Detection', frame)\n",
    "    \n",
    "\n",
    "    if cv2.waitKey(20) & 0xFF == ord('c'):\n",
    "        frame_name = \"out/Parcial_frame_{}.png\".format(frame_index)\n",
    "        cv2.imwrite(frame_name, frame)\n",
    "        frame_index += 1\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee6b2256-7ca3-49dd-bff2-31a11e53391b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'OpenGL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mOpenGL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mGL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mOpenGL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mGLUT\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mOpenGL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mGLU\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'OpenGL'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from OpenGL.GL import *\n",
    "from OpenGL.GLUT import *\n",
    "from OpenGL.GLU import *\n",
    "from objloader import OBJ  # Asumiendo que tienes un archivo objloader.py para cargar modelos obj\n",
    "\n",
    "OVERLAY_SIZE_PER = 1\n",
    "\n",
    "# Check for camera calibration data\n",
    "if not os.path.exists('calibration.pckl'):\n",
    "    print(\"You need to calibrate the camera before\")\n",
    "    exit()\n",
    "else:\n",
    "    f = open('calibration.pckl', 'rb')\n",
    "    cameraMatrix, distCoeffs = pickle.load(f)\n",
    "    f.close()\n",
    "    if cameraMatrix is None or distCoeffs is None:\n",
    "        print(\"Something went wrong. Recalibrate the camera\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "# Cargar el modelo 3D\n",
    "obj = OBJ(\"path/to/your/model.obj\")\n",
    "\n",
    "\n",
    "def draw_points(img, pts):\n",
    "    \"\"\" Draw the points in the image\"\"\"\n",
    "\n",
    "    pts = np.int32(pts).reshape(-1, 2)\n",
    "\n",
    "    # img = cv2.drawContours(img, [pts], -1, (255, 255, 0), -3)\n",
    "\n",
    "    for p in pts:\n",
    "        cv2.circle(img, (p[0], p[1]), 5, (255, 0, 255), -1)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def draw_augmented_overlay(pts_1, overlay_image, image):\n",
    "    \"\"\"Overlay the image 'overlay_image' onto the image 'image'\"\"\"\n",
    "\n",
    "    # Define the squares of the overlay_image image to be drawn:\n",
    "    pts_2 = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],\n",
    "                        [0, overlay_image.shape[0]]])\n",
    "\n",
    "    # Draw border to see the limits of the image:\n",
    "    cv2.rectangle(overlay_image, (0, 0), (overlay_image.shape[1], overlay_image.shape[0]), (255, 255, 0), 10)\n",
    "\n",
    "    # Create the transformation matrix:\n",
    "    M = cv2.getPerspectiveTransform(pts_2, pts_1)\n",
    "\n",
    "    # Transform the overlay_image image using the transformation matrix M:\n",
    "    dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))\n",
    "    #cv2.imshow(\"dst_image\", dst_image)\n",
    "\n",
    "    # Create the mask:\n",
    "    dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Compute bitwise conjunction using the calculated mask:\n",
    "    image_masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "    #cv2.imshow(\"image_masked\", image_masked)\n",
    "\n",
    "    # Add the two images to create the resulting image:\n",
    "    result = cv2.add(dst_image, image_masked)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Create the dictionary object and the parameters:\n",
    "#aruco_dictionary = cv2.aruco.Dictionary_get(cv2.aruco.DICT_7X7_250)\n",
    "#parameters = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "dictionary = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_7X7_250)\n",
    "parameters =  cv2.aruco.DetectorParameters()\n",
    "detector = cv2.aruco.ArucoDetector(dictionary, parameters)\n",
    "\n",
    "# Create video capture object 'capture' to be used to capture frames from the first connected camera:\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame by frame from the video capture object 'capture':\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # We convert the frame to grayscale:\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect markers:\n",
    "    corners, ids, rejectedImgPoints = detector.detectMarkers(gray_frame) #cv2.aruco.detectMarkers(gray_frame, aruco_dictionary, parameters=parameters)\n",
    "\n",
    "    # Draw detected markers:\n",
    "    frame = cv2.aruco.drawDetectedMarkers(image=frame, corners=corners, ids=ids, borderColor=(0, 255, 0))\n",
    "\n",
    "    # Draw rejected markers:\n",
    "    # frame = cv2.aruco.drawDetectedMarkers(image=frame, corners=rejectedImgPoints, borderColor=(0, 0, 255))\n",
    "\n",
    "    if ids is not None:\n",
    "        # rvecs and tvecs are the rotation and translation vectors respectively, for each of the markers in corners.\n",
    "        rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, 1, cameraMatrix, distCoeffs)\n",
    "\n",
    "        for rvec, tvec in zip(rvecs, tvecs):\n",
    "            # Note: The marker coordinate system is centered on the center of the marker\n",
    "            # The coordinates of the four corners of the marker (in its own coordinate system) are:\n",
    "            # 1: (-markerLength/2, markerLength/2, 0)\n",
    "            # 2: (markerLength/2, markerLength/2, 0)\n",
    "            # 3: (markerLength/2, -markerLength/2, 0)\n",
    "            # 4: (-markerLength/2, -markerLength/2, 0)\n",
    "            # Define the points where you want the image to be overlaid (remember: marker coordinate system):\n",
    "            desired_points = np.float32(\n",
    "                [[-1 / 2, 1 / 2, 0], [1 / 2, 1 / 2, 0], [1 / 2, -1 / 2, 0], [-1 / 2, -1 / 2, 0]]) * OVERLAY_SIZE_PER\n",
    "\n",
    "            # Proyectar puntos y overlay del modelo 3D\n",
    "            projected_desired_points, jac = cv2.projectPoints(desired_points, rvecs, tvecs, cameraMatrix, distCoeffs)\n",
    "\n",
    "            # Obtener la matriz de vista utilizando los parámetros de cámara\n",
    "            view_matrix = cv2.Rodrigues(rvec)[0]\n",
    "\n",
    "            # Renderizar el modelo 3D\n",
    "            glLoadIdentity()\n",
    "            glLoadMatrixd(view_matrix)\n",
    "            glTranslatef(tvec[0][0], tvec[0][1], tvec[0][2])  # Ajusta según las coordenadas del marcador\n",
    "\n",
    "            glEnable(GL_DEPTH_TEST)\n",
    "            obj.render()\n",
    "\n",
    "            glDisable(GL_DEPTH_TEST)\n",
    "\n",
    "  # Display the resulting augmented frame:\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Press 'q' to exit:\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything:\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f3755c-cbd4-41fb-b457-c3b8054482c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
