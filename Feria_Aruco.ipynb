{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96e632f3-ece6-4ba3-be23-0d88c779d745",
   "metadata": {},
   "source": [
    "<h1>Trabajdo Realizado para la Feria</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20666ae8-32f4-4301-8359-0e4a5343eb6f",
   "metadata": {},
   "source": [
    "<h2>Integrantes</h2>\n",
    "<p>Luis Caballero 8-9231440<br>\n",
    "Ángel Cilli<br>\n",
    "Jaime Acosta</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aabf84c-45bb-4253-8f2b-94a30a4bbce0",
   "metadata": {},
   "source": [
    "<p><b>Idea o Concepto:</b>Trabajaremos un reconocedor de \"personal\" dentro del equipo, un Aruco distinto para Jaime Acosta y Luis Caballero, que cuando sean mostrados a la cámara el programa ejecutará distintos enfoques con Aruco.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55855017-2911-44f6-baea-67b6b33d5520",
   "metadata": {},
   "source": [
    "<h2>Detector del Personal</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20498b3e-fd79-48c7-91ad-babb795c0b93",
   "metadata": {},
   "source": [
    "<p>Para el detector de personal usaremos el diccionario <b>DISC_4x4_1000</b>b><br>\n",
    "Marcado ID 15 → Luis Caballero<br>\n",
    "Marcador ID 13 → Jaime Acosta</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34b38b1-ef69-4303-bba0-73f64e5f3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTACIONES\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#AruCO\n",
    "\n",
    "OVERLAY_SIZE_PER = 1\n",
    "\n",
    "# Check for camera calibration data\n",
    "if not os.path.exists('calibration.pckl'):\n",
    "    print(\"Necesitas Calibrar tu Cámara para un buen uso\")\n",
    "    exit()\n",
    "else:\n",
    "    f = open('calibration.pckl', 'rb')\n",
    "    cameraMatrix, distCoeffs = pickle.load(f)\n",
    "    f.close()\n",
    "    if cameraMatrix is None or distCoeffs is None:\n",
    "        print(\"Alguien salio mal. Recalibra tu cámara\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "# Create the ArUco dictionary and parameters:\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_1000) #Detector de Personal\n",
    "aruco_dict2 = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_5X5_1000) #Imagen 3D\n",
    "aruco_dict3 = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_1000) #Filtros\n",
    "parameters = cv2.aruco.DetectorParameters()\n",
    "\n",
    "# Create the video capture object:\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "frame_index = 0;\n",
    "\n",
    "while video_capture.isOpened():\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(gray_frame, aruco_dict, parameters=parameters)\n",
    "\n",
    "    if ids is not None:\n",
    "        for i in range(len(ids)):\n",
    "            if ids[i] == 15:\n",
    "                # Mensaje de bienvenida para Luis Caballero\n",
    "                cv2.putText(img=frame, text=\"Bienvenido Luis\", org=(10, 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1,\n",
    "            color=(102, 102, 255), thickness=2)\n",
    "                #aqui deberia ir lo de filtros o video\n",
    "            \n",
    "            elif ids[i] == 13:\n",
    "                # Mensaje de bienvenida para Jaime Acosta\n",
    "                cv2.putText(img=frame, text=\"Bienvenido Jaime\", org=(10, 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1,\n",
    "            color=(102, 102, 255), thickness=2)\n",
    "                #aqui deberia ir lo del 3D\n",
    "                \n",
    "            else:\n",
    "                #Mensaje de no esta registrado\n",
    "                cv2.putText(img=frame, text=\"Quien tu eres!?\", org=(10, 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1,\n",
    "            color=(102, 102, 255), thickness=2)\n",
    "                \n",
    "\n",
    "    cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "    cv2.imshow('ArUco Marker and Face Detection', frame)\n",
    "    \n",
    "\n",
    "    if cv2.waitKey(20) & 0xFF == ord('c'):\n",
    "        frame_name = \"out/Parcial_frame_{}.png\".format(frame_index)\n",
    "        cv2.imwrite(frame_name, frame)\n",
    "        frame_index += 1\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e177a4-3e86-4c01-b9e0-4cb15df95551",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a891efa-ef1b-4e97-b6f5-7dadf0a1cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "OVERLAY_SIZE_PER = 1\n",
    "\n",
    "# Check for camera calibration data\n",
    "if not os.path.exists('calibration.pckl'):\n",
    "    print(\"You need to calibrate the camera before\")\n",
    "    exit()\n",
    "else:\n",
    "    f = open('calibration.pckl', 'rb')\n",
    "    cameraMatrix, distCoeffs = pickle.load(f)\n",
    "    f.close()\n",
    "    if cameraMatrix is None or distCoeffs is None:\n",
    "        print(\"Something went wrong. Recalibrate the camera\")\n",
    "        exit()\n",
    "\n",
    "# Load the video overlay:\n",
    "video_path = \"Img/SheidexPapure.mp4\"  # Cambia a la ruta de tu video\n",
    "cap_overlay = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Function to get the next frame from the overlay video\n",
    "def get_next_overlay_frame():\n",
    "    ret, frame = cap_overlay.read()\n",
    "    if not ret:\n",
    "        cap_overlay.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        ret, frame = cap_overlay.read()\n",
    "    return frame\n",
    "\n",
    "def draw_augmented_overlay(pts_1, overlay_image, image):\n",
    "    \"\"\"Overlay the image 'overlay_image' onto the image 'image'\"\"\"\n",
    "\n",
    "    # Define the squares of the overlay_image image to be drawn:\n",
    "    pts_2 = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],\n",
    "                        [0, overlay_image.shape[0]]])\n",
    "\n",
    "    # Draw border to see the limits of the image:\n",
    "    cv2.rectangle(overlay_image, (0, 0), (overlay_image.shape[1], overlay_image.shape[0]), (255, 255, 0), 10)\n",
    "\n",
    "    # Create the transformation matrix:\n",
    "    M = cv2.getPerspectiveTransform(pts_2, pts_1)\n",
    "\n",
    "    # Transform the overlay_image image using the transformation matrix M:\n",
    "    dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Create the mask:\n",
    "    dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Compute bitwise conjunction using the calculated mask:\n",
    "    image_masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Add the two images to create the resulting image:\n",
    "    result = cv2.add(dst_image, image_masked)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Create the dictionary object and the parameters:\n",
    "dictionary = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_7X7_250)\n",
    "parameters = cv2.aruco.DetectorParameters()\n",
    "detector = cv2.aruco.ArucoDetector(dictionary, parameters)\n",
    "\n",
    "# Create video capture object 'capture' to be used to capture frames from the first connected camera:\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame by frame from the video capture object 'capture':\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # We convert the frame to grayscale:\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect markers:\n",
    "    corners, ids, rejectedImgPoints = detector.detectMarkers(gray_frame)\n",
    "\n",
    "    # Draw detected markers:\n",
    "    frame = cv2.aruco.drawDetectedMarkers(image=frame, corners=corners, ids=ids, borderColor=(0, 255, 0))\n",
    "\n",
    "    if ids is not None:\n",
    "        # rvecs and tvecs are the rotation and translation vectors respectively, for each of the markers in corners.\n",
    "        rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, 1, cameraMatrix, distCoeffs)\n",
    "\n",
    "        for rvec, tvec in zip(rvecs, tvecs):\n",
    "            # Note: The marker coordinate system is centered on the center of the marker\n",
    "            # The coordinates of the four corners of the marker (in its own coordinate system) are:\n",
    "            # 1: (-markerLength/2, markerLength/2, 0)\n",
    "            # 2: (markerLength/2, markerLength/2, 0)\n",
    "            # 3: (markerLength/2, -markerLength/2, 0)\n",
    "            # 4: (-markerLength/2, -markerLength/2, 0)\n",
    "            # Define the points where you want the image to be overlaid (remember: marker coordinate system):\n",
    "            desired_points = np.float32(\n",
    "                [[-1 / 2, 1 / 2, 0], [1 / 2, 1 / 2, 0], [1 / 2, -1 / 2, 0], [-1 / 2, -1 / 2, 0]]) * OVERLAY_SIZE_PER\n",
    "\n",
    "            # Project the points:\n",
    "            projected_desired_points, jac = cv2.projectPoints(desired_points, rvecs, tvecs, cameraMatrix, distCoeffs)\n",
    "\n",
    "            # Get the next frame from the overlay video\n",
    "            overlay_frame = get_next_overlay_frame()\n",
    "\n",
    "            # Overlay the video frame onto the camera frame\n",
    "            frame = draw_augmented_overlay(projected_desired_points, overlay_frame, frame)\n",
    "\n",
    "    # Display the resulting augmented frame:\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Press 'q' to exit:\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything:\n",
    "capture.release()\n",
    "cap_overlay.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e866d15-ad29-4f62-be76-0460813248f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Verificar acceso basado en el marcador ArUco\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m corners, ids \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_access\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Mostrar el frame con el marcador dibujado\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[26], line 14\u001b[0m, in \u001b[0;36mcheck_access\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_access\u001b[39m(frame):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Convertir a escala de grises\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Detectar marcadores ArUco\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     corners, ids, rejected \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39maruco\u001b[38;5;241m.\u001b[39mdetectMarkers(gray, aruco_dict, parameters\u001b[38;5;241m=\u001b[39maruco_params)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Configuración del sistema de marcadores ArUco\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "aruco_params = cv2.aruco.DetectorParameters()\n",
    "\n",
    "# IDs permitidos para el acceso y sus respectivos nombres\n",
    "allowed_marker_ids = {13: \"Jaime Acosta\", 15: \"Luis Caballero\"}\n",
    "\n",
    "# Función para verificar si el marcador permitido está presente y dar la bienvenida\n",
    "def check_access(frame):\n",
    "    # Convertir a escala de grises\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detectar marcadores ArUco\n",
    "    corners, ids, rejected = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=aruco_params)\n",
    "\n",
    "    # Si se detectan marcadores\n",
    "    if ids is not None:\n",
    "        for marker_id in ids:\n",
    "            if marker_id[0] in allowed_marker_ids:\n",
    "                # Obtener el nombre asociado al ID del marcador\n",
    "                name = allowed_marker_ids[marker_id[0]]\n",
    "                if marker_id[0] == 15:\n",
    "                    text_color = (0, 0, 0)\n",
    "                    bienvenida(frame, name, marker_id[0], text_color)\n",
    "                    \n",
    "                if marker_id[0] == 13:\n",
    "                    text_color = (255, 0, 0)\n",
    "                    bienvenida(frame, name, marker_id[0], text_color)       \n",
    "                \n",
    "        return corners, ids\n",
    "\n",
    "    # Imprimir mensaje de acceso denegado si no se detecta ningún marcador permitido\n",
    "    text_color =(0, 255, 0)\n",
    "    denegado(frame, \"Desconocido\", -1, text_color)\n",
    "    return None, None\n",
    "\n",
    "# Configuración de la cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capturar un frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Verificar acceso basado en el marcador ArUco\n",
    "    corners, ids = check_access(frame)\n",
    "\n",
    "    # Mostrar el frame con el marcador dibujado\n",
    "    if corners is not None:\n",
    "        cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "    cv2.imshow('Acceso basado en marcador ArUco', frame)\n",
    "\n",
    "    # Salir del bucle si se presiona 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "def bienvenida(frame, name, marker_id, text_color):\n",
    "    cv2.putText(img=frame, text=f\"Bienvenido, {name} (ID {marker_id}). Acceso permitido.\",\n",
    "                org=(10, 30), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=0.6,\n",
    "                color=text_color, thickness=2)\n",
    "    \n",
    "def denegado(frame, name, marker_id, text_color):\n",
    "    cv2.putText(img=frame, text=f\"{name} (ID {marker_id}). Quien eres?\",\n",
    "                org=(10, 30), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=0.6,\n",
    "                color=text_color, thickness=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98836396-222c-409b-b779-e973e0651567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import aruco\n",
    "\n",
    "# Inicializar el diccionario 4x4\n",
    "dictionary_4x4 = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "\n",
    "# Inicializar el diccionario 5x5\n",
    "dictionary_5x5 = aruco.getPredefinedDictionary(aruco.DICT_5X5_50)\n",
    "\n",
    "# Inicializar el diccionario 6x6\n",
    "dictionary_6x6 = aruco.getPredefinedDictionary(aruco.DICT_6X6_250)\n",
    "\n",
    "# Cargar el clasificador Haar Cascade para la detección facial\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Inicializar la cámara (asegúrate de tener una cámara disponible)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capturar un fotograma de la cámara\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convertir el fotograma a escala de grises\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detectar marcadores ArUco en la imagen\n",
    "    corners, ids, _ = aruco.detectMarkers(gray, dictionary_4x4)\n",
    "\n",
    "    if ids is not None and len(ids) > 0:\n",
    "        # Si se detecta un marcador con ID 15 (Luis Caballero)\n",
    "        if 15 in ids:\n",
    "            # Cambiar al diccionario 5x5\n",
    "            dictionary = dictionary_5x5\n",
    "\n",
    "            # Mostrar video si se detecta el marcador con ID 20\n",
    "            if 20 in ids:\n",
    "                # Coloca aquí el código para mostrar el video\n",
    "                pass\n",
    "\n",
    "        # Si se detecta un marcador con ID 13 (Jaime Acosta)\n",
    "        elif 13 in ids:\n",
    "            # Cambiar al diccionario 6x6\n",
    "            dictionary = dictionary_6x6\n",
    "\n",
    "            # Si se detecta el marcador con ID 10, aplicar el filtro de blur en la cara\n",
    "            if 10 in ids:\n",
    "                # Detectar caras en la imagen\n",
    "                faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "                # Aplicar blur a las caras detectadas\n",
    "                for (x, y, w, h) in faces:\n",
    "                    face_roi = frame[y:y + h, x:x + w]\n",
    "                    face_roi = cv2.GaussianBlur(face_roi, (99, 99), 30)\n",
    "\n",
    "                    # Reemplazar la región de la cara con blur en el fotograma original\n",
    "                    frame[y:y + face_roi.shape[0], x:x + face_roi.shape[1]] = face_roi\n",
    "\n",
    "        # Dibujar los marcadores detectados en la imagen original\n",
    "        aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "    # Mostrar la imagen resultante\n",
    "    cv2.imshow('ARUCO Access Control', frame)\n",
    "\n",
    "    # Romper el bucle si se presiona la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar los recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26b3d55a-4e64-4a71-a5bd-a4e05e96081e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db54e00-4214-4f64-8095-ffbf1deccefb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
