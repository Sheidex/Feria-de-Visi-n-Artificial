{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96e632f3-ece6-4ba3-be23-0d88c779d745",
   "metadata": {},
   "source": [
    "<h1>Trabajdo Realizado para la Feria</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20666ae8-32f4-4301-8359-0e4a5343eb6f",
   "metadata": {},
   "source": [
    "<h2>Integrantes</h2>\n",
    "<p>Luis Caballero 8-9231440<br>\n",
    "Ángel Cilli E-8-182257<br>\n",
    "Jaime Acosta 8-971-833</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aabf84c-45bb-4253-8f2b-94a30a4bbce0",
   "metadata": {},
   "source": [
    "<p><b>Idea o Concepto:</b>Trabajaremos un reconocedor de \"personal\" dentro del equipo, un Aruco distinto para Jaime Acosta y Luis Caballero, que cuando sean mostrados a la cámara el programa ejecutará distintos enfoques con Aruco.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55855017-2911-44f6-baea-67b6b33d5520",
   "metadata": {},
   "source": [
    "<h2>Detector del Personal</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20498b3e-fd79-48c7-91ad-babb795c0b93",
   "metadata": {},
   "source": [
    "<p>Para el detector de personal usaremos el diccionario <b>DISC_4x4_1000</b>b><br>\n",
    "Marcado ID 15 → Luis Caballero<br>\n",
    "Marcador ID 13 → Jaime Acosta</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb1e3f-17b3-46c6-a2a2-b39aa4126d27",
   "metadata": {},
   "source": [
    "<h1>Programa Limpio/Completo</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49fd7517-d0a7-4cbd-9c8a-1a62c0f0af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importaciones \n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "\n",
    "# Funcion de mensjae de bienvenida\n",
    "def bienvenida(name, frame):\n",
    "    cv2.putText(img=frame, text=f\"Bienvenido, {name} Acceso permitido.\",\n",
    "                org=(10, 30), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=0.6,\n",
    "                color=(255, 255, 255), thickness=2)\n",
    "\n",
    "# Funcion para control del tiempo en pantalla\n",
    "def delay(window_name, frame, delay):\n",
    "    cv2.imshow(window_name, frame)\n",
    "    cv2.waitKey(delay * 1000)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Funcion para el video en el marcador\n",
    "def overlay_video(pts_1, overlay_image, image):\n",
    "    pts_2 = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],\n",
    "                        [0, overlay_image.shape[0]]])\n",
    "    M = cv2.getPerspectiveTransform(pts_2, pts_1)\n",
    "    dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))\n",
    "    dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "    image_masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "    result = cv2.add(dst_image, image_masked)\n",
    "    return result\n",
    "\n",
    "# Funcion para la mascara en la cara\n",
    "def meme(frame):\n",
    "    face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    img_cuerno = cv2.imread('Img/meme.png', 1)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        x1 = x\n",
    "        x2 = x + w\n",
    "        y1 = y - h\n",
    "        y2 = y + h\n",
    "        cuerno_resized = cv2.resize(img_cuerno, (w, h))\n",
    "        frame[y:y + h, x:x + w] = cv2.addWeighted(frame[y:y + h, x:x + w], 1, cuerno_resized, 1, 0)\n",
    "    return frame\n",
    "\n",
    "# Main\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    principal_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)# dicionario para el acceso\n",
    "    luis_dict_5x5 = aruco.getPredefinedDictionary(aruco.DICT_5X5_50)#diccionario para video en marcador\n",
    "    jaime_dict_6x6 = aruco.getPredefinedDictionary(aruco.DICT_6X6_50)#diccioanrio para mascaras en a cara\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    video_path = 'Img/muchacho.mp4'\n",
    "    cap_overlay = cv2.VideoCapture(video_path)\n",
    "    overlay_image_path = 'Img/sigma.png'\n",
    "    overlay_image = cv2.imread(overlay_image_path, cv2.IMREAD_UNCHANGED)\n",
    "    overlay_image = cv2.resize(overlay_image, (100, 100))\n",
    "\n",
    "    def get_next_overlay_frame():\n",
    "        ret, frame = cap_overlay.read()\n",
    "        if not ret:\n",
    "            cap_overlay.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            ret, frame = cap_overlay.read()\n",
    "        return frame\n",
    "\n",
    "    def draw_augmented_overlay(pts_1, overlay_image, image):\n",
    "        pts_2 = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],\n",
    "                            [0, overlay_image.shape[0]]])\n",
    "        cv2.rectangle(overlay_image, (0, 0), (overlay_image.shape[1], overlay_image.shape[0]), (255, 255, 0), 10)\n",
    "        M = cv2.getPerspectiveTransform(pts_2, pts_1)\n",
    "        dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))\n",
    "        dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)\n",
    "        ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "        image_masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "        result = cv2.add(dst_image, image_masked)\n",
    "        return result\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, principal_dict)\n",
    "\n",
    "        if ids is not None and 15 in ids:\n",
    "            bienvenida(\"Luis\", frame)\n",
    "            delay(\"Diccionario 5x5 - Video en Marcaror\", frame, 5)\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                corners, ids, _ = aruco.detectMarkers(gray, luis_dict_5x5)\n",
    "\n",
    "                if ids is not None and 10 in ids:\n",
    "                    overlay_frame = get_next_overlay_frame()\n",
    "                    if overlay_frame is not None:\n",
    "                        frame = draw_augmented_overlay(corners[0][0], overlay_frame, frame)\n",
    "\n",
    "                elif ids is not None and 15 in ids:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break\n",
    "\n",
    "                cv2.imshow(\"Diccionario 5x5 - Video en Marcaror\", frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27:\n",
    "                    break\n",
    "\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, principal_dict)\n",
    "\n",
    "        if ids is not None and 13 in ids:\n",
    "            bienvenida(\"Jaime\", frame)\n",
    "            delay(\"Diccionario 6x6 - Mascara en la Cara\", frame, 5)\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                corners, ids, _ = aruco.detectMarkers(gray, jaime_dict_6x6)\n",
    "\n",
    "                if ids is not None and 20 in ids:\n",
    "                    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        face = frame[y:y + h, x:x + w]\n",
    "                        face = cv2.GaussianBlur(face, (99, 99), 30)\n",
    "                        frame[y:y + h, x:x + w] = face\n",
    "                        face_height, face_width, _ = face.shape\n",
    "                        overlay_image_resized = cv2.resize(overlay_image, (face_width, face_height))\n",
    "                        frame[y:y + h, x:x + w] = cv2.addWeighted(frame[y:y + h, x:x + w], 1.0, overlay_image_resized[:, :, :3], 0.7, 0)\n",
    "\n",
    "                elif ids is not None and 8 in ids:\n",
    "                    meme(frame)\n",
    "\n",
    "                elif ids is not None and 15 in ids:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break\n",
    "\n",
    "                cv2.imshow(\"Diccionario 6x6 - Mascara en la Cara\", frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27:\n",
    "                    break\n",
    "\n",
    "        cv2.imshow(\"Original\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cap_overlay.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf57b5c-564d-4bdf-84f1-d01ee852aa0c",
   "metadata": {},
   "source": [
    "<h1>Historial de códigos</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7571d3de-966c-4aaf-9665-94992759b8f9",
   "metadata": {},
   "source": [
    "<p>En esta parte encontrará los programas que se hicieron para in probando cada una de las partes que se desea hacer, antes de realizar o unirlo en un unico codigo limpio</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34b38b1-ef69-4303-bba0-73f64e5f3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTACIONES\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#AruCO\n",
    "\n",
    "OVERLAY_SIZE_PER = 1\n",
    "\n",
    "# Check for camera calibration data\n",
    "if not os.path.exists('calibration.pckl'):\n",
    "    print(\"Necesitas Calibrar tu Cámara para un buen uso\")\n",
    "    exit()\n",
    "else:\n",
    "    f = open('calibration.pckl', 'rb')\n",
    "    cameraMatrix, distCoeffs = pickle.load(f)\n",
    "    f.close()\n",
    "    if cameraMatrix is None or distCoeffs is None:\n",
    "        print(\"Alguien salio mal. Recalibra tu cámara\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "# Create the ArUco dictionary and parameters:\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_1000) #Detector de Personal\n",
    "aruco_dict2 = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_5X5_1000) #Imagen 3D\n",
    "aruco_dict3 = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_1000) #Filtros\n",
    "parameters = cv2.aruco.DetectorParameters()\n",
    "\n",
    "# Create the video capture object:\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "frame_index = 0;\n",
    "\n",
    "while video_capture.isOpened():\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(gray_frame, aruco_dict, parameters=parameters)\n",
    "\n",
    "    if ids is not None:\n",
    "        for i in range(len(ids)):\n",
    "            if ids[i] == 15:\n",
    "                # Mensaje de bienvenida para Luis Caballero\n",
    "                cv2.putText(img=frame, text=\"Bienvenido Luis\", org=(10, 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1,\n",
    "            color=(102, 102, 255), thickness=2)\n",
    "                #aqui deberia ir lo de filtros o video\n",
    "            \n",
    "            elif ids[i] == 13:\n",
    "                # Mensaje de bienvenida para Jaime Acosta\n",
    "                cv2.putText(img=frame, text=\"Bienvenido Jaime\", org=(10, 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1,\n",
    "            color=(102, 102, 255), thickness=2)\n",
    "                #aqui deberia ir lo del 3D\n",
    "                \n",
    "            else:\n",
    "                #Mensaje de no esta registrado\n",
    "                cv2.putText(img=frame, text=\"Quien tu eres!?\", org=(10, 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=1,\n",
    "            color=(102, 102, 255), thickness=2)\n",
    "                \n",
    "\n",
    "    cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "    cv2.imshow('ArUco Marker and Face Detection', frame)\n",
    "    \n",
    "\n",
    "    if cv2.waitKey(20) & 0xFF == ord('c'):\n",
    "        frame_name = \"out/Parcial_frame_{}.png\".format(frame_index)\n",
    "        cv2.imwrite(frame_name, frame)\n",
    "        frame_index += 1\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e177a4-3e86-4c01-b9e0-4cb15df95551",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a891efa-ef1b-4e97-b6f5-7dadf0a1cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "OVERLAY_SIZE_PER = 1\n",
    "\n",
    "# Check for camera calibration data\n",
    "if not os.path.exists('calibration.pckl'):\n",
    "    print(\"You need to calibrate the camera before\")\n",
    "    exit()\n",
    "else:\n",
    "    f = open('calibration.pckl', 'rb')\n",
    "    cameraMatrix, distCoeffs = pickle.load(f)\n",
    "    f.close()\n",
    "    if cameraMatrix is None or distCoeffs is None:\n",
    "        print(\"Something went wrong. Recalibrate the camera\")\n",
    "        exit()\n",
    "\n",
    "# Load the video overlay:\n",
    "video_path = \"Img/SheidexPapure.mp4\"  # Cambia a la ruta de tu video\n",
    "cap_overlay = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Function to get the next frame from the overlay video\n",
    "def get_next_overlay_frame():\n",
    "    ret, frame = cap_overlay.read()\n",
    "    if not ret:\n",
    "        cap_overlay.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        ret, frame = cap_overlay.read()\n",
    "    return frame\n",
    "\n",
    "def draw_augmented_overlay(pts_1, overlay_image, image):\n",
    "    \"\"\"Overlay the image 'overlay_image' onto the image 'image'\"\"\"\n",
    "\n",
    "    # Define the squares of the overlay_image image to be drawn:\n",
    "    pts_2 = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],\n",
    "                        [0, overlay_image.shape[0]]])\n",
    "\n",
    "    # Draw border to see the limits of the image:\n",
    "    cv2.rectangle(overlay_image, (0, 0), (overlay_image.shape[1], overlay_image.shape[0]), (255, 255, 0), 10)\n",
    "\n",
    "    # Create the transformation matrix:\n",
    "    M = cv2.getPerspectiveTransform(pts_2, pts_1)\n",
    "\n",
    "    # Transform the overlay_image image using the transformation matrix M:\n",
    "    dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Create the mask:\n",
    "    dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Compute bitwise conjunction using the calculated mask:\n",
    "    image_masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Add the two images to create the resulting image:\n",
    "    result = cv2.add(dst_image, image_masked)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Create the dictionary object and the parameters:\n",
    "dictionary = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_7X7_250)\n",
    "parameters = cv2.aruco.DetectorParameters()\n",
    "detector = cv2.aruco.ArucoDetector(dictionary, parameters)\n",
    "\n",
    "# Create video capture object 'capture' to be used to capture frames from the first connected camera:\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame by frame from the video capture object 'capture':\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # We convert the frame to grayscale:\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect markers:\n",
    "    corners, ids, rejectedImgPoints = detector.detectMarkers(gray_frame)\n",
    "\n",
    "    # Draw detected markers:\n",
    "    frame = cv2.aruco.drawDetectedMarkers(image=frame, corners=corners, ids=ids, borderColor=(0, 255, 0))\n",
    "\n",
    "    if ids is not None:\n",
    "        # rvecs and tvecs are the rotation and translation vectors respectively, for each of the markers in corners.\n",
    "        rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, 1, cameraMatrix, distCoeffs)\n",
    "\n",
    "        for rvec, tvec in zip(rvecs, tvecs):\n",
    "            # Note: The marker coordinate system is centered on the center of the marker\n",
    "            # The coordinates of the four corners of the marker (in its own coordinate system) are:\n",
    "            # 1: (-markerLength/2, markerLength/2, 0)\n",
    "            # 2: (markerLength/2, markerLength/2, 0)\n",
    "            # 3: (markerLength/2, -markerLength/2, 0)\n",
    "            # 4: (-markerLength/2, -markerLength/2, 0)\n",
    "            # Define the points where you want the image to be overlaid (remember: marker coordinate system):\n",
    "            desired_points = np.float32(\n",
    "                [[-1 / 2, 1 / 2, 0], [1 / 2, 1 / 2, 0], [1 / 2, -1 / 2, 0], [-1 / 2, -1 / 2, 0]]) * OVERLAY_SIZE_PER\n",
    "\n",
    "            # Project the points:\n",
    "            projected_desired_points, jac = cv2.projectPoints(desired_points, rvecs, tvecs, cameraMatrix, distCoeffs)\n",
    "\n",
    "            # Get the next frame from the overlay video\n",
    "            overlay_frame = get_next_overlay_frame()\n",
    "\n",
    "            # Overlay the video frame onto the camera frame\n",
    "            frame = draw_augmented_overlay(projected_desired_points, overlay_frame, frame)\n",
    "\n",
    "    # Display the resulting augmented frame:\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Press 'q' to exit:\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything:\n",
    "capture.release()\n",
    "cap_overlay.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26b3d55a-4e64-4a71-a5bd-a4e05e96081e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4db54e00-4214-4f64-8095-ffbf1deccefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "\n",
    "def welcome_message(name, frame):\n",
    "    cv2.putText(img=frame, text=f\"Bienvenido, {name} Acceso permitido.\",\n",
    "                org=(10, 30), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=0.6,\n",
    "                color=(255, 255, 255), thickness=2)\n",
    "\n",
    "def main():\n",
    "    # Configuración de la cámara\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Diccionario 4x4 para Luis\n",
    "    principal_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "    \n",
    "    # Diccionario 5x5 para Luis\n",
    "    luis_dict_5x5 = aruco.getPredefinedDictionary(aruco.DICT_5X5_50)\n",
    "\n",
    "    # Diccionario 6x6 para Jaime\n",
    "    jaime_dict_6x6 = aruco.getPredefinedDictionary(aruco.DICT_6X6_50)\n",
    "\n",
    "    # Cargamos el clasificador de caras de OpenCV\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convertir la imagen a escala de grises\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detectar marcadores 4x4\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, principal_dict)\n",
    "\n",
    "        if ids is not None and 15 in ids:\n",
    "            welcome_message(\"Luis\", frame)\n",
    "            \n",
    "            # Abrir nueva ventana para el diccionario 5x5\n",
    "            cv2.destroyAllWindows()\n",
    "            cv2.namedWindow(\"Diccionario 5x5\") #Cambiar \n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detectar marcadores 5x5\n",
    "                corners, ids, _ = aruco.detectMarkers(gray, luis_dict_5x5)\n",
    "\n",
    "                if ids is not None and 10 in ids:\n",
    "                    # Aplicar blur en la cara\n",
    "                    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)) #en vez de ser borrado, podria ser marcaras\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        face = frame[y:y + h, x:x + w]\n",
    "                        face = cv2.GaussianBlur(face, (99, 99), 30)\n",
    "                        frame[y:y + h, x:x + w] = face\n",
    "\n",
    "                elif ids is not None and 15 in ids:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break  # Volver a la ventana anterior\n",
    "\n",
    "                cv2.imshow(\"Diccionario 5x5\", frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "                    break\n",
    "\n",
    "        # Detectar marcadores 6x6 para Jaime\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, principal_dict)\n",
    "\n",
    "        if ids is not None and 13 in ids:\n",
    "            welcome_message(\"Jaime\", frame)\n",
    "\n",
    "            # Abrir nueva ventana para el marcador 20\n",
    "            cv2.destroyAllWindows()\n",
    "            cv2.namedWindow(\"Diccionario 6x6\")\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detectar marcadores 6x6\n",
    "                corners, ids, _ = aruco.detectMarkers(gray, jaime_dict_6x6)\n",
    "\n",
    "                if ids is not None and 20 in ids: #Qui se puede colocar otro\n",
    "                    # Colocar la imagen en la cara\n",
    "                    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        # Coordenadas de la región de la cara\n",
    "                        face_region = frame[y:y + h, x:x + w]\n",
    "\n",
    "                        # Cargar la imagen\n",
    "                        image = cv2.imread(\"Img/yemil.jpg\")\n",
    "\n",
    "                        # Verificar si la imagen se cargó correctamente\n",
    "                        if image is not None:\n",
    "                            # Ajustar el tamaño de la imagen al tamaño de la cara\n",
    "                            image = cv2.resize(image, (w, h))\n",
    "\n",
    "                            # Superponer la imagen en la región de la cara\n",
    "                            frame[y:y + h, x:x + w] = cv2.addWeighted(face_region, 1, image, 0.7, 0)\n",
    "\n",
    "                elif ids is not None and 15 in ids:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break  # Volver a la ventana anterior\n",
    "\n",
    "                cv2.imshow(\"Diccionario 6x6\", frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "                    break\n",
    "\n",
    "        cv2.imshow(\"Original\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2459c135-8f72-4e7e-a68b-cedc5699c466",
   "metadata": {},
   "source": [
    "V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6f1d0aa-eb42-43dd-84a6-cfad98c67907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def bienvenida(name, frame):\n",
    "    cv2.putText(img=frame, text=f\"Bienvenido, {name} Acceso permitido.\",\n",
    "                org=(10, 30), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=0.6,\n",
    "                color=(255, 255, 255), thickness=2)\n",
    "\n",
    "def delay(window_name, frame, delay):\n",
    "    cv2.imshow(window_name, frame)\n",
    "    cv2.waitKey(delay * 1000)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    # Configuración de la cámara\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Diccionario 4x4 para Luis\n",
    "    principal_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "    \n",
    "    # Diccionario 5x5 para Luis\n",
    "    luis_dict_5x5 = aruco.getPredefinedDictionary(aruco.DICT_5X5_50)\n",
    "\n",
    "    # Diccionario 6x6 para Jaime\n",
    "    jaime_dict_6x6 = aruco.getPredefinedDictionary(aruco.DICT_6X6_50)\n",
    "\n",
    "    # Cargamos el clasificador de caras de OpenCV\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convertir la imagen a escala de grises\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detectar marcadores 4x4\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, principal_dict)\n",
    "\n",
    "        if ids is not None and 15 in ids:\n",
    "            bienvenida(\"Luis\", frame)\n",
    "            delay(\"Diccionario 5x5\", frame, 5)\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detectar marcadores 5x5\n",
    "                corners, ids, _ = aruco.detectMarkers(gray, luis_dict_5x5)\n",
    "\n",
    "                if ids is not None and 10 in ids:\n",
    "                    # Aplicar blur en la cara\n",
    "                    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        face = frame[y:y + h, x:x + w]\n",
    "                        face = cv2.GaussianBlur(face, (99, 99), 30)\n",
    "                        frame[y:y + h, x:x + w] = face\n",
    "\n",
    "                elif ids is not None and 15 in ids:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break  # Volver a la ventana anterior\n",
    "\n",
    "                cv2.imshow(\"Diccionario 5x5\", frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "                    break\n",
    "\n",
    "        # Detectar marcadores 6x6 para Jaime\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, principal_dict)\n",
    "\n",
    "        if ids is not None and 13 in ids:\n",
    "            bienvenida(\"Jaime\", frame)\n",
    "            delay(\"Diccionario 6x6\", frame, 5)\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detectar marcadores 6x6\n",
    "                corners, ids, _ = aruco.detectMarkers(gray, jaime_dict_6x6)\n",
    "\n",
    "                if ids is not None and 20 in ids:\n",
    "                    # Colocar la imagen en la cara\n",
    "                    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        # Coordenadas de la región de la cara\n",
    "                        face_region = frame[y:y + h, x:x + w]\n",
    "\n",
    "                        # Cargar la imagen\n",
    "                        image = cv2.imread(\"Img/yemil.jpg\")\n",
    "\n",
    "                        # Verificar si la imagen se cargó correctamente\n",
    "                        if image is not None:\n",
    "                            # Ajustar el tamaño de la imagen al tamaño de la cara\n",
    "                            image = cv2.resize(image, (w, h))\n",
    "\n",
    "                            # Superponer la imagen en la región de la cara\n",
    "                            frame[y:y + h, x:x + w] = cv2.addWeighted(face_region, 1, image, 0.7, 0)\n",
    "\n",
    "                elif ids is not None and 15 in ids:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break  # Volver a la ventana anterior\n",
    "\n",
    "                cv2.imshow(\"Diccionario 6x6\", frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "                    break\n",
    "\n",
    "        cv2.imshow(\"Original\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4e9de-f799-4dcc-832d-30217b76a6e6",
   "metadata": {},
   "source": [
    "intento de que cuando entra como jaime muestre un video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55fdc5a4-224e-4a6e-973d-80ad8e392ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def bienvenida(name, frame):\n",
    "    cv2.putText(img=frame, text=f\"Bienvenido, {name} Acceso permitido.\",\n",
    "                org=(10, 30), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=0.6,\n",
    "                color=(255, 255, 255), thickness=2)\n",
    "\n",
    "def delay(window_name, frame, delay):\n",
    "    cv2.imshow(window_name, frame)\n",
    "    cv2.waitKey(delay * 1000)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def overlay_video(pts_1, overlay_image, image):\n",
    "    \"\"\"Overlay the video 'overlay_image' onto the image 'image'\"\"\"\n",
    "\n",
    "    # Define the squares of the overlay_image image to be drawn:\n",
    "    pts_2 = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],\n",
    "                        [0, overlay_image.shape[0]]])\n",
    "\n",
    "    # Create the transformation matrix:\n",
    "    M = cv2.getPerspectiveTransform(pts_2, pts_1)\n",
    "\n",
    "    # Transform the overlay_image image using the transformation matrix M:\n",
    "    dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Create the mask:\n",
    "    dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Compute bitwise conjunction using the calculated mask:\n",
    "    image_masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Add the two images to create the resulting image:\n",
    "    result = cv2.add(dst_image, image_masked)\n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    # Configuración de la cámara\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Diccionario 4x4 para Luis\n",
    "    principal_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "\n",
    "    # Diccionario 5x5 para Luis\n",
    "    luis_dict_5x5 = aruco.getPredefinedDictionary(aruco.DICT_5X5_50)\n",
    "\n",
    "    # Diccionario 6x6 para Jaime\n",
    "    jaime_dict_6x6 = aruco.getPredefinedDictionary(aruco.DICT_6X6_50)\n",
    "\n",
    "    # Cargamos el clasificador de caras de OpenCV\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Cargar el video\n",
    "    video_path = 'Img/SheidexPapure.mp4'  # Cambia esto por la ruta de tu video\n",
    "    cap_overlay = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convertir la imagen a escala de grises\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detectar marcadores 4x4\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, principal_dict)\n",
    "\n",
    "        if ids is not None and 15 in ids:\n",
    "            bienvenida(\"Luis\", frame)\n",
    "            delay(\"Diccionario 5x5\", frame, 5)\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detectar marcadores 5x5\n",
    "                corners, ids, _ = aruco.detectMarkers(gray, luis_dict_5x5)\n",
    "\n",
    "                if ids is not None and 10 in ids:\n",
    "                    # Get the next frame from the overlay video\n",
    "                    ret, overlay_frame = cap_overlay.read()\n",
    "                    if ret:\n",
    "                        # Overlay the video frame onto the camera frame\n",
    "                        frame = overlay_video(corners[0][0], overlay_frame, frame)\n",
    "\n",
    "                elif ids is not None and 15 in ids:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break  # Volver a la ventana anterior\n",
    "\n",
    "                cv2.imshow(\"Diccionario 5x5\", frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "                    break\n",
    "\n",
    "        # Detectar marcadores 6x6 para Jaime\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, principal_dict)\n",
    "\n",
    "        if ids is not None and 13 in ids:\n",
    "            bienvenida(\"Jaime\", frame)\n",
    "            delay(\"Diccionario 6x6\", frame, 5)\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detectar marcadores 6x6\n",
    "                corners, ids, _ = aruco.detectMarkers(gray, jaime_dict_6x6)\n",
    "\n",
    "                if ids is not None and 20 in ids:\n",
    "                    # Colocar la imagen en la cara\n",
    "                    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        # Coordenadas de la región de la cara\n",
    "                        face_region = frame[y:y + h, x:x + w]\n",
    "\n",
    "                        # Cargar la imagen\n",
    "                        image = cv2.imread(\"Img/yemil.jpg\")\n",
    "\n",
    "                        # Verificar si la imagen se cargó correctamente\n",
    "                        if image is not None:\n",
    "                            # Ajustar el tamaño de la imagen al tamaño de la cara\n",
    "                            image = cv2.resize(image, (w, h))\n",
    "\n",
    "                            # Superponer la imagen en la región de la cara\n",
    "                            frame[y:y + h, x:x + w] = cv2.addWeighted(face_region, 1, image, 0.7, 0)\n",
    "\n",
    "                elif ids is not None and 15 in ids:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break  # Volver a la ventana anterior\n",
    "\n",
    "                cv2.imshow(\"Diccionario 6x6\", frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "                    break\n",
    "\n",
    "        cv2.imshow(\"Original\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cap_overlay.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccebf6e3-b2ed-4769-872a-0e509efcb341",
   "metadata": {},
   "source": [
    "<h1>V#4</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9b48cc-f78e-4d3c-9285-35c185f18422",
   "metadata": {},
   "source": [
    "<p>Esta parte ya logra el acceso por aruco de Luis y Jaime, y con el de Luis ya logra reproducir un video</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fda90921-64f9-48cd-b8a4-c2a2974cd53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def bienvenida(name, frame):\n",
    "    cv2.putText(img=frame, text=f\"Bienvenido, {name} Acceso permitido.\",\n",
    "                org=(10, 30), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=0.6,\n",
    "                color=(255, 255, 255), thickness=2)\n",
    "\n",
    "def delay(window_name, frame, delay):\n",
    "    cv2.imshow(window_name, frame)\n",
    "    cv2.waitKey(delay * 1000)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def overlay_video(pts_1, overlay_image, image):\n",
    "    \"\"\"Overlay the video 'overlay_image' onto the image 'image'\"\"\"\n",
    "\n",
    "    # Define the squares of the overlay_image image to be drawn:\n",
    "    pts_2 = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],\n",
    "                        [0, overlay_image.shape[0]]])\n",
    "\n",
    "    # Create the transformation matrix:\n",
    "    M = cv2.getPerspectiveTransform(pts_2, pts_1)\n",
    "\n",
    "    # Transform the overlay_image image using the transformation matrix M:\n",
    "    dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Create the mask:\n",
    "    dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Compute bitwise conjunction using the calculated mask:\n",
    "    image_masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Add the two images to create the resulting image:\n",
    "    result = cv2.add(dst_image, image_masked)\n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    # Configuración de la cámara\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Diccionario 4x4 para Luis\n",
    "    principal_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "\n",
    "    # Diccionario 5x5 para Luis\n",
    "    luis_dict_5x5 = aruco.getPredefinedDictionary(aruco.DICT_5X5_50)\n",
    "\n",
    "    # Diccionario 6x6 para Jaime\n",
    "    jaime_dict_6x6 = aruco.getPredefinedDictionary(aruco.DICT_6X6_50)\n",
    "\n",
    "    # Cargamos el clasificador de caras de OpenCV\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Cargar el video\n",
    "    video_path = 'Img/SheidexPapure.mp4'  # Cambia esto por la ruta de tu video\n",
    "    cap_overlay = cv2.VideoCapture(video_path)\n",
    "\n",
    "    def get_next_overlay_frame():\n",
    "        ret, frame = cap_overlay.read()\n",
    "        if not ret:\n",
    "            cap_overlay.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            ret, frame = cap_overlay.read()\n",
    "        return frame\n",
    "\n",
    "    def draw_augmented_overlay(pts_1, overlay_image, image):\n",
    "        \"\"\"Overlay the image 'overlay_image' onto the image 'image'\"\"\"\n",
    "\n",
    "        # Define the squares of the overlay_image image to be drawn:\n",
    "        pts_2 = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],\n",
    "                            [0, overlay_image.shape[0]]])\n",
    "\n",
    "        # Draw border to see the limits of the image:\n",
    "        cv2.rectangle(overlay_image, (0, 0), (overlay_image.shape[1], overlay_image.shape[0]), (255, 255, 0), 10)\n",
    "\n",
    "        # Create the transformation matrix:\n",
    "        M = cv2.getPerspectiveTransform(pts_2, pts_1)\n",
    "\n",
    "        # Transform the overlay_image image using the transformation matrix M:\n",
    "        dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "        # Create the mask:\n",
    "        dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)\n",
    "        ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # Compute bitwise conjunction using the calculated mask:\n",
    "        image_masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "        # Add the two images to create the resulting image:\n",
    "        result = cv2.add(dst_image, image_masked)\n",
    "        return result\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convertir la imagen a escala de grises\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detectar marcadores 4x4\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, principal_dict)\n",
    "\n",
    "        if ids is not None and 15 in ids:\n",
    "            bienvenida(\"Luis\", frame)\n",
    "            delay(\"Diccionario 5x5\", frame, 5)\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detectar marcadores 5x5\n",
    "                corners, ids, _ = aruco.detectMarkers(gray, luis_dict_5x5)\n",
    "\n",
    "                if ids is not None and 10 in ids:\n",
    "                    # Get the next frame from the overlay video\n",
    "                    overlay_frame = get_next_overlay_frame()\n",
    "                    if overlay_frame is not None:\n",
    "                        # Overlay the video frame onto the camera frame\n",
    "                        frame = draw_augmented_overlay(corners[0][0], overlay_frame, frame)\n",
    "\n",
    "                elif ids is not None and 15 in ids:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break  # Volver a la ventana anterior\n",
    "\n",
    "                cv2.imshow(\"Diccionario 5x5\", frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "                    break\n",
    "\n",
    "        # Detectar marcadores 6x6 para Jaime\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, principal_dict)\n",
    "\n",
    "        if ids is not None and 13 in ids:\n",
    "            bienvenida(\"Jaime\", frame)\n",
    "            delay(\"Diccionario 6x6\", frame, 5)\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detectar marcadores 6x6\n",
    "                corners, ids, _ = aruco.detectMarkers(gray, jaime_dict_6x6)\n",
    "\n",
    "                if ids is not None and 20 in ids:\n",
    "                    # Colocar la imagen en la cara\n",
    "                    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        # Coordenadas de la región de la cara\n",
    "                        face_region = frame[y:y + h, x:x + w]\n",
    "\n",
    "                        # Cargar la imagen\n",
    "                        image = cv2.imread(\"Img/yemil.jpg\")\n",
    "\n",
    "                        # Verificar si la imagen se cargó correctamente\n",
    "                        if image is not None:\n",
    "                            # Ajustar el tamaño de la imagen al tamaño de la cara\n",
    "                            image = cv2.resize(image, (w, h))\n",
    "\n",
    "                            # Superponer la imagen en la región de la cara\n",
    "                            frame[y:y + h, x:x + w] = cv2.addWeighted(face_region, 1, image, 0.7, 0)\n",
    "\n",
    "                elif ids is not None and 15 in ids:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break  # Volver a la ventana anterior\n",
    "\n",
    "                cv2.imshow(\"Diccionario 6x6\", frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "                    break\n",
    "\n",
    "        cv2.imshow(\"Original\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cap_overlay.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1b66e6-a1ab-45f4-809f-a83d469c5f67",
   "metadata": {},
   "source": [
    "<h1>V#5</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873dd4c0-2fad-4b7a-a609-aec6b3113921",
   "metadata": {},
   "source": [
    "<p>cuando entra como Jaime, debe ejecutar un filtro de payaso</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c361281b-53e4-42f6-b13b-e39f4d8b7dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def bienvenida(name, frame):\n",
    "    cv2.putText(img=frame, text=f\"Bienvenido, {name} Acceso permitido.\",\n",
    "                org=(10, 30), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=0.6,\n",
    "                color=(255, 255, 255), thickness=2)\n",
    "\n",
    "def delay(window_name, frame, delay):\n",
    "    cv2.imshow(window_name, frame)\n",
    "    cv2.waitKey(delay * 1000)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def overlay_video(pts_1, overlay_image, image):\n",
    "    \"\"\"Overlay the video 'overlay_image' onto the image 'image'\"\"\"\n",
    "\n",
    "    # Define the squares of the overlay_image image to be drawn:\n",
    "    pts_2 = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],\n",
    "                        [0, overlay_image.shape[0]]])\n",
    "\n",
    "    # Create the transformation matrix:\n",
    "    M = cv2.getPerspectiveTransform(pts_2, pts_1)\n",
    "\n",
    "    # Transform the overlay_image image using the transformation matrix M:\n",
    "    dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Create the mask:\n",
    "    dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Compute bitwise conjunction using the calculated mask:\n",
    "    image_masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Add the two images to create the resulting image:\n",
    "    result = cv2.add(dst_image, image_masked)\n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    # Configuración de la cámara\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Diccionario 4x4 para Luis\n",
    "    principal_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "\n",
    "    # Diccionario 5x5 para Luis\n",
    "    luis_dict_5x5 = aruco.getPredefinedDictionary(aruco.DICT_5X5_50)\n",
    "\n",
    "    # Diccionario 6x6 para Jaime\n",
    "    jaime_dict_6x6 = aruco.getPredefinedDictionary(aruco.DICT_6X6_50)\n",
    "\n",
    "    # Cargamos el clasificador de caras de OpenCV\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Cargar el video\n",
    "    video_path = 'Img/SheidexPapure.mp4'  # Cambia esto por la ruta de tu video\n",
    "    cap_overlay = cv2.VideoCapture(video_path)\n",
    "\n",
    "    def get_next_overlay_frame():\n",
    "        ret, frame = cap_overlay.read()\n",
    "        if not ret:\n",
    "            cap_overlay.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            ret, frame = cap_overlay.read()\n",
    "        return frame\n",
    "\n",
    "    def draw_augmented_overlay(pts_1, overlay_image, image):\n",
    "        \"\"\"Overlay the image 'overlay_image' onto the image 'image'\"\"\"\n",
    "\n",
    "        # Define the squares of the overlay_image image to be drawn:\n",
    "        pts_2 = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],\n",
    "                            [0, overlay_image.shape[0]]])\n",
    "\n",
    "        # Draw border to see the limits of the image:\n",
    "        cv2.rectangle(overlay_image, (0, 0), (overlay_image.shape[1], overlay_image.shape[0]), (255, 255, 0), 10)\n",
    "\n",
    "        # Create the transformation matrix:\n",
    "        M = cv2.getPerspectiveTransform(pts_2, pts_1)\n",
    "\n",
    "        # Transform the overlay_image image using the transformation matrix M:\n",
    "        dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "        # Create the mask:\n",
    "        dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)\n",
    "        ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # Compute bitwise conjunction using the calculated mask:\n",
    "        image_masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "        # Add the two images to create the resulting image:\n",
    "        result = cv2.add(dst_image, image_masked)\n",
    "        return result\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convertir la imagen a escala de grises\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detectar marcadores 4x4\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, principal_dict)\n",
    "\n",
    "        if ids is not None and 15 in ids:\n",
    "            bienvenida(\"Luis\", frame)\n",
    "            delay(\"Diccionario 5x5\", frame, 5)\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detectar marcadores 5x5\n",
    "                corners, ids, _ = aruco.detectMarkers(gray, luis_dict_5x5)\n",
    "\n",
    "                if ids is not None and 10 in ids:\n",
    "                    # Get the next frame from the overlay video\n",
    "                    overlay_frame = get_next_overlay_frame()\n",
    "                    if overlay_frame is not None:\n",
    "                        # Overlay the video frame onto the camera frame\n",
    "                        frame = draw_augmented_overlay(corners[0][0], overlay_frame, frame)\n",
    "\n",
    "                elif ids is not None and 15 in ids:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break  # Volver a la ventana anterior\n",
    "\n",
    "                cv2.imshow(\"Diccionario 5x5\", frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "                    break\n",
    "\n",
    "        # Detectar marcadores 6x6 para Jaime\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, principal_dict)\n",
    "\n",
    "        if ids is not None and 13 in ids:\n",
    "            bienvenida(\"Jaime\", frame)\n",
    "            delay(\"Diccionario 6x6\", frame, 5)\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detectar marcadores 6x6\n",
    "                corners, ids, _ = aruco.detectMarkers(gray, jaime_dict_6x6)\n",
    "\n",
    "                if ids is not None and 20 in ids:\n",
    "                   # Aplicar blur en la cara\n",
    "                    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)) #en vez de ser borrado, podria ser marcaras\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        face = frame[y:y + h, x:x + w]\n",
    "                        face = cv2.GaussianBlur(face, (99, 99), 30)\n",
    "                        frame[y:y + h, x:x + w] = face\n",
    "\n",
    "\n",
    "                elif ids is not None and 15 in ids:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break  # Volver a la ventana anterior\n",
    "\n",
    "                cv2.imshow(\"Diccionario 6x6\", frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "                    break\n",
    "\n",
    "        cv2.imshow(\"Original\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cap_overlay.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098765af-9a29-416c-9c9d-fc0ffc8a7e42",
   "metadata": {},
   "source": [
    "<h1>V6</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e815654-e7d5-48f5-a518-faca6c970a7b",
   "metadata": {},
   "source": [
    "<p>Ya muestra la imagen en el rostro, pero con un fondo negro, ya que se intento colocar un filtro blur y luego montar la imagen, pero no se pudo</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff9b208-c66a-495d-8555-25a9a2b7b88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def bienvenida(name, frame):\n",
    "    cv2.putText(img=frame, text=f\"Bienvenido, {name} Acceso permitido.\",\n",
    "                org=(10, 30), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=0.6,\n",
    "                color=(255, 255, 255), thickness=2)\n",
    "\n",
    "def delay(window_name, frame, delay):\n",
    "    cv2.imshow(window_name, frame)\n",
    "    cv2.waitKey(delay * 1000)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def overlay_video(pts_1, overlay_image, image):\n",
    "    # Define the squares of the overlay_image image to be drawn:\n",
    "    pts_2 = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],\n",
    "                        [0, overlay_image.shape[0]]])\n",
    "\n",
    "    # Create the transformation matrix:\n",
    "    M = cv2.getPerspectiveTransform(pts_2, pts_1)\n",
    "\n",
    "    # Transform the overlay_image image using the transformation matrix M:\n",
    "    dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Create the mask:\n",
    "    dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Compute bitwise conjunction using the calculated mask:\n",
    "    image_masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Add the two images to create the resulting image:\n",
    "    result = cv2.add(dst_image, image_masked)\n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    # Configuración de la cámara\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Diccionario 4x4 para Luis\n",
    "    principal_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "\n",
    "    # Diccionario 5x5 para Luis\n",
    "    luis_dict_5x5 = aruco.getPredefinedDictionary(aruco.DICT_5X5_50)\n",
    "\n",
    "    # Diccionario 6x6 para Jaime\n",
    "    jaime_dict_6x6 = aruco.getPredefinedDictionary(aruco.DICT_6X6_50)\n",
    "\n",
    "    # Cargamos el clasificador de caras de OpenCV\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Cargar el video\n",
    "    video_path = 'Img/muchacho.mp4'  # Cambia esto por la ruta de tu video\n",
    "    cap_overlay = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Cargar la imagen para superponer\n",
    "    overlay_image_path = 'Img/sigma.png'\n",
    "    overlay_image = cv2.imread(overlay_image_path, cv2.IMREAD_UNCHANGED)\n",
    "    overlay_image = cv2.resize(overlay_image, (100, 100))  # Ajusta el tamaño según sea necesario\n",
    "\n",
    "    def get_next_overlay_frame():\n",
    "        ret, frame = cap_overlay.read()\n",
    "        if not ret:\n",
    "            cap_overlay.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            ret, frame = cap_overlay.read()\n",
    "        return frame\n",
    "\n",
    "    def draw_augmented_overlay(pts_1, overlay_image, image):\n",
    "        \"\"\"Overlay the image 'overlay_image' onto the image 'image'\"\"\"\n",
    "\n",
    "        # Define the squares of the overlay_image image to be drawn:\n",
    "        pts_2 = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],\n",
    "                            [0, overlay_image.shape[0]]])\n",
    "\n",
    "        # Draw border to see the limits of the image:\n",
    "        cv2.rectangle(overlay_image, (0, 0), (overlay_image.shape[1], overlay_image.shape[0]), (255, 255, 0), 10)\n",
    "\n",
    "        # Create the transformation matrix:\n",
    "        M = cv2.getPerspectiveTransform(pts_2, pts_1)\n",
    "\n",
    "        # Transform the overlay_image image using the transformation matrix M:\n",
    "        dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "        # Create the mask:\n",
    "        dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)\n",
    "        ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # Compute bitwise conjunction using the calculated mask:\n",
    "        image_masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "        # Add the two images to create the resulting image:\n",
    "        result = cv2.add(dst_image, image_masked)\n",
    "        return result\n",
    "\n",
    "\n",
    "        # Add the two images to create the resulting image:\n",
    "        result = cv2.add(dst_image, image_masked)\n",
    "\n",
    "        return result\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convertir la imagen a escala de grises\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detectar marcadores 4x4\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, principal_dict)\n",
    "\n",
    "        if ids is not None and 15 in ids:\n",
    "            bienvenida(\"Luis\", frame)\n",
    "            delay(\"Diccionario 5x5\", frame, 5)\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detectar marcadores 5x5\n",
    "                corners, ids, _ = aruco.detectMarkers(gray, luis_dict_5x5)\n",
    "\n",
    "                if ids is not None and 10 in ids:\n",
    "                    # Get the next frame from the overlay video\n",
    "                    overlay_frame = get_next_overlay_frame()\n",
    "                    if overlay_frame is not None:\n",
    "                        # Overlay the video frame onto the camera frame\n",
    "                        frame = draw_augmented_overlay(corners[0][0], overlay_frame, frame)\n",
    "\n",
    "                elif ids is not None and 15 in ids:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break  # Volver a la ventana anterior\n",
    "\n",
    "                cv2.imshow(\"Diccionario 5x5\", frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "                    break\n",
    "\n",
    "        # Detectar marcadores 6x6 para Jaime\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, principal_dict)\n",
    "\n",
    "        if ids is not None and 13 in ids:\n",
    "            bienvenida(\"Jaime\", frame)\n",
    "            delay(\"Diccionario 6x6\", frame, 5)\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detectar marcadores 6x6\n",
    "                corners, ids, _ = aruco.detectMarkers(gray, jaime_dict_6x6)\n",
    "\n",
    "                if ids is not None and 20 in ids:\n",
    "                    # Aplicar blur en la cara\n",
    "                    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        face = frame[y:y + h, x:x + w]\n",
    "                        face = cv2.GaussianBlur(face, (99, 99), 30)\n",
    "                        frame[y:y + h, x:x + w] = face\n",
    "\n",
    "                        # Superponer la imagen en la cara\n",
    "                        face_height, face_width, _ = face.shape\n",
    "                        overlay_image_resized = cv2.resize(overlay_image, (face_width, face_height))\n",
    "                        frame[y:y + h, x:x + w] = cv2.addWeighted(frame[y:y + h, x:x + w], 1.0, overlay_image_resized[:, :, :3], 0.7, 0)\n",
    "\n",
    "                if ids is not None and 8 in ids:\n",
    "                    # Aplicar blur en la cara\n",
    "                    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        face = frame[y:y + h, x:x + w]\n",
    "                        face = cv2.GaussianBlur(face, (99, 99), 30)\n",
    "                        frame[y:y + h, x:x + w] = face\n",
    "\n",
    "                        # Superponer la imagen en la cara\n",
    "                        face_height, face_width, _ = face.shape\n",
    "                        overlay_image_resized = cv2.resize(overlay_image, (face_width, face_height))\n",
    "                        frame[y:y + h, x:x + w] = cv2.addWeighted(frame[y:y + h, x:x + w], 1.0, overlay_image_resized[:, :, :3], 0.7, 0)\n",
    "\n",
    "\n",
    "                elif ids is not None and 15 in ids:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break  # Volver a la ventana anterior\n",
    "\n",
    "                cv2.imshow(\"Diccionario 6x6\", frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "                    break\n",
    "\n",
    "        cv2.imshow(\"Original\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cap_overlay.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fd3f34-50d6-4a2c-89c7-4a0a235c000c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c194bf23-d7cc-41dd-bfb3-f0877d446bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "#import time\n",
    "\n",
    "def bienvenida(name, frame):\n",
    "    cv2.putText(img=frame, text=f\"Bienvenido, {name} Acceso permitido.\",\n",
    "                org=(10, 30), fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=0.6,\n",
    "                color=(255, 255, 255), thickness=2)\n",
    "\n",
    "def delay(window_name, frame, delay):\n",
    "    cv2.imshow(window_name, frame)\n",
    "    cv2.waitKey(delay * 1000)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def overlay_video(pts_1, overlay_image, image):\n",
    "    # Define the squares of the overlay_image image to be drawn:\n",
    "    pts_2 = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],\n",
    "                        [0, overlay_image.shape[0]]])\n",
    "\n",
    "    # Create the transformation matrix:\n",
    "    M = cv2.getPerspectiveTransform(pts_2, pts_1)\n",
    "\n",
    "    # Transform the overlay_image image using the transformation matrix M:\n",
    "    dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Create the mask:\n",
    "    dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Compute bitwise conjunction using the calculated mask:\n",
    "    image_masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Add the two images to create the resulting image:\n",
    "    result = cv2.add(dst_image, image_masked)\n",
    "    return result\n",
    "\n",
    "#FUNCION DE MASCARA\n",
    "def meme(frame):\n",
    "    # Load the cascade classifier for face detection:\n",
    "    face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "    img_cuerno = cv2.imread('Img/meme.png', 1)  # Use 1 to read the image in color\n",
    "\n",
    "    # Convert the frame to grayscale:\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces using the 'detectMultiScale()' function:\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        \n",
    "        x1 = x\n",
    "        x2 = x + w\n",
    "        y1 = y - h  \n",
    "        y2 = y + h  \n",
    "\n",
    "        \n",
    "        cuerno_resized = cv2.resize(img_cuerno, (w, h))\n",
    "\n",
    "        # Superpose the cuerno on the frame\n",
    "        frame[y:y + h, x:x + w] = cv2.addWeighted(frame[y:y + h, x:x + w], 1, cuerno_resized, 1, 0)\n",
    "\n",
    "    return frame\n",
    "\n",
    "def main():\n",
    "    # Configuración de la cámara\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Diccionario 4x4 para Luis\n",
    "    principal_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "\n",
    "    # Diccionario 5x5 para Luis\n",
    "    luis_dict_5x5 = aruco.getPredefinedDictionary(aruco.DICT_5X5_50)\n",
    "\n",
    "    # Diccionario 6x6 para Jaime\n",
    "    jaime_dict_6x6 = aruco.getPredefinedDictionary(aruco.DICT_6X6_50)\n",
    "\n",
    "    # Cargamos el clasificador de caras de OpenCV\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Cargar el video\n",
    "    video_path = 'Img/muchacho.mp4'  # Cambia esto por la ruta de tu video\n",
    "    cap_overlay = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Cargar la imagen para superponer\n",
    "    overlay_image_path = 'Img/sigma.png'\n",
    "    overlay_image = cv2.imread(overlay_image_path, cv2.IMREAD_UNCHANGED)\n",
    "    overlay_image = cv2.resize(overlay_image, (100, 100))  # Ajusta el tamaño según sea necesario\n",
    "\n",
    "\n",
    "    def get_next_overlay_frame():\n",
    "        ret, frame = cap_overlay.read()\n",
    "        if not ret:\n",
    "            cap_overlay.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            ret, frame = cap_overlay.read()\n",
    "        return frame\n",
    "\n",
    "    def draw_augmented_overlay(pts_1, overlay_image, image):\n",
    "        \"\"\"Overlay the image 'overlay_image' onto the image 'image'\"\"\"\n",
    "\n",
    "        # Define the squares of the overlay_image image to be drawn:\n",
    "        pts_2 = np.float32([[0, 0], [overlay_image.shape[1], 0], [overlay_image.shape[1], overlay_image.shape[0]],\n",
    "                            [0, overlay_image.shape[0]]])\n",
    "\n",
    "        # Draw border to see the limits of the image:\n",
    "        cv2.rectangle(overlay_image, (0, 0), (overlay_image.shape[1], overlay_image.shape[0]), (255, 255, 0), 10)\n",
    "\n",
    "        # Create the transformation matrix:\n",
    "        M = cv2.getPerspectiveTransform(pts_2, pts_1)\n",
    "\n",
    "        # Transform the overlay_image image using the transformation matrix M:\n",
    "        dst_image = cv2.warpPerspective(overlay_image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "        # Create the mask:\n",
    "        dst_image_gray = cv2.cvtColor(dst_image, cv2.COLOR_BGR2GRAY)\n",
    "        ret, mask = cv2.threshold(dst_image_gray, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # Compute bitwise conjunction using the calculated mask:\n",
    "        image_masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "        # Add the two images to create the resulting image:\n",
    "        result = cv2.add(dst_image, image_masked)\n",
    "        return result\n",
    "\n",
    "\n",
    "        # Add the two images to create the resulting image:\n",
    "        result = cv2.add(dst_image, image_masked)\n",
    "\n",
    "        return result\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convertir la imagen a escala de grises\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detectar marcadores 4x4\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, principal_dict)\n",
    "\n",
    "        if ids is not None and 15 in ids:\n",
    "            bienvenida(\"Luis\", frame)\n",
    "            delay(\"Diccionario 5x5\", frame, 5)\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detectar marcadores 5x5\n",
    "                corners, ids, _ = aruco.detectMarkers(gray, luis_dict_5x5)\n",
    "\n",
    "                if ids is not None and 10 in ids:\n",
    "                    # Get the next frame from the overlay video\n",
    "                    overlay_frame = get_next_overlay_frame()\n",
    "                    if overlay_frame is not None:\n",
    "                        # Overlay the video frame onto the camera frame\n",
    "                        frame = draw_augmented_overlay(corners[0][0], overlay_frame, frame)\n",
    "\n",
    "                elif ids is not None and 15 in ids:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break  # Volver a la ventana anterior\n",
    "\n",
    "                cv2.imshow(\"Diccionario 5x5\", frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "                    break\n",
    "\n",
    "        # Detectar marcadores 6x6 para Jaime\n",
    "        corners, ids, _ = aruco.detectMarkers(gray, principal_dict)\n",
    "\n",
    "        if ids is not None and 13 in ids:\n",
    "            bienvenida(\"Jaime\", frame)\n",
    "            delay(\"Diccionario 6x6\", frame, 5)\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detectar marcadores 6x6\n",
    "                corners, ids, _ = aruco.detectMarkers(gray, jaime_dict_6x6)\n",
    "\n",
    "                if ids is not None and 20 in ids:\n",
    "                    # Aplicar blur en la cara\n",
    "                    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        face = frame[y:y + h, x:x + w]\n",
    "                        face = cv2.GaussianBlur(face, (99, 99), 30)\n",
    "                        frame[y:y + h, x:x + w] = face\n",
    "\n",
    "                        # Superponer la imagen en la cara\n",
    "                        face_height, face_width, _ = face.shape\n",
    "                        overlay_image_resized = cv2.resize(overlay_image, (face_width, face_height))\n",
    "                        frame[y:y + h, x:x + w] = cv2.addWeighted(frame[y:y + h, x:x + w], 1.0, overlay_image_resized[:, :, :3], 0.7, 0)\n",
    "\n",
    "                elif ids is not None and 8 in ids:\n",
    "                    meme(frame)\n",
    "\n",
    "                elif ids is not None and 15 in ids:\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break  # Volver a la ventana anterior\n",
    "\n",
    "                cv2.imshow(\"Diccionario 6x6\", frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "                    break\n",
    "\n",
    "        cv2.imshow(\"Original\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # Presionar Esc para salir\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cap_overlay.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
